::: hljs-center

论文阅读笔记——SuMa++：基于LiDAR的高效语义SLAM

:::

论文：[SuMa++](http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2019iros.pdf)
代码：[semantic_suma](https://github.com/PRBonn/semantic_suma)

### 摘要

可靠并精确的定位和建图是大多数自动驾驶和机器人系统的关键组成部分。除了环境的几何信息之外，语义信息在智能导航方面也起着重要作用。在大多数现实环境中，由于存在动态物体，传统的基于环境几何信息的方法很难实现可靠并精确的定位与建图。这些传统几何方法方法常常因动态物体的存在出现定位偏移以及建图扭曲的情况。
在本文中，我们提出一种新的基于语义信息的激光雷达SLAM系统来更好地解决真实环境中的定位与建图问题。该系统通过语义分割激光雷达点云来获取点云级的密集语义信息，并将该语义信息集成到激光雷达SLAM中来提高激光雷达的定位与建图精度。通过基于深度学习的卷积神经网络，我们的方法可以十分高效地在激光雷达“范围图（range image）”上进行语义分割，并对整个激光雷达点云进行语义标记。通过结合几何深度信息，我们的方法可以进一步提升语义分割的精度。基于带语义标记的激光雷达点云，我们的方法能够构建带有语义信息且全局一致的密集“面元（surfel）”语义地图。基于该语义地图，我们提出的算法能够可靠地过滤移除动态物体，而且还可以通过语义约束来进一步提高投影匹配ICP的位姿估计精度。我们利用KITTI数据集中的公路（road）数据集和里程计数据集（odometry）来测试我们提出的语义SLAM系统。该数据集（尤其是KITTI公路数据集）中包含大量的行驶中的汽车。实验结果表明，在真实的动态环境中我们的语义SLAM方法具有更高的定位精度以及鲁棒性。

![title](https://github.com/hyxhope/picture/blob/master/Selection_003.png)


本文的主要贡献是将语义集成到基于面元（类似于一个“体素）的地图表示中的方法，以及利用这些语义标签过滤动态对象的方法。

### 方法
