# 
论文阅读笔记——SuMa++：基于LiDAR的高效语义SLAM
---


论文：[SuMa++](http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2019iros.pdf)
代码：[semantic_suma](https://github.com/PRBonn/semantic_suma)

### 摘要

&emsp;&emsp;可靠并精确的定位和建图是大多数自动驾驶和机器人系统的关键组成部分。除了环境的几何信息之外，语义信息在智能导航方面也起着重要作用。在大多数现实环境中，由于存在动态物体，传统的基于环境几何信息的方法很难实现可靠并精确的定位与建图。这些传统几何方法方法常常因动态物体的存在出现定位偏移以及建图扭曲的情况。
&emsp;&emsp;在本文中，我们提出一种新的基于语义信息的激光雷达SLAM系统来更好地解决真实环境中的定位与建图问题。该系统通过语义分割激光雷达点云来获取点云级的密集语义信息，并将该语义信息集成到激光雷达SLAM中来提高激光雷达的定位与建图精度。通过基于深度学习的卷积神经网络，我们的方法可以十分高效地在激光雷达“范围图（range image）”上进行语义分割，并对整个激光雷达点云进行语义标记。通过结合几何深度信息，我们的方法可以进一步提升语义分割的精度。基于带语义标记的激光雷达点云，我们的方法能够构建带有语义信息且全局一致的密集“面元（surfel）”语义地图。基于该语义地图，我们提出的算法能够可靠地过滤移除动态物体，而且还可以通过语义约束来进一步提高投影匹配ICP的位姿估计精度。我们利用KITTI数据集中的公路（road）数据集和里程计数据集（odometry）来测试我们提出的语义SLAM系统。该数据集（尤其是KITTI公路数据集）中包含大量的行驶中的汽车。实验结果表明，在真实的动态环境中我们的语义SLAM方法具有更高的定位精度以及鲁棒性。

![title](https://github.com/hyxhope/picture/blob/master/suma%2B%2B/suma%2B%2B_1.png)


图1 仅使用LiDAR数据通过我们的方法生成的KITTI数据集的语义图。该图由具有以相应颜色表示的类别标签的面元表示。总体而言，与其他非语义SLAM相比，我们的语义SLAM方法能够提供高质量的语义地图。




&emsp;&emsp;本文的主要贡献是将语义集成到基于面元（类似于一个“体素）的地图表示中的方法，以及利用这些语义标签过滤动态对象的方法。

### 方法

&emsp;&emsp;我们的语义SLAM方法的基础是基于Surfel的Mapping（SuMa）管道，我们对其进行了扩展通过整合语义提供的语义信息如图所示，使用FCN RangeNet++进行细分在图2中。逐点标签由RangeNet ++提供使用点云的球形投影。 然后，此信息将用于过滤动态对象并添加扫描注册的语义约束，从而提高了SuMa估计姿势的鲁棒性和准确性。

![title](https://github.com/hyxhope/picture/blob/master/suma%2B%2B/suma%2B%2B_2.png)


图2 我们所提方法的流程概述。我们以一种紧凑的方式将语义预测集成到SuMa方法中：（1）输入仅为LiDAR扫描P。（2）在处理原始点云P之前，我们首先使用RangeNet ++的语义分段来预测每个点并生成原始语义掩码Sraw。（3）给定原始掩码，我们在预处理模块中使用多类泛洪填充生成精炼的语义图SD。（4）在地图更新过程中，我们添加了一个动态检测和删除模块，该模块检查新观测值SD与世界模型SM之间的语义一致性，并删除异常值。（5）同时，我们在ICP流程中添加了额外的语义约束，以使其对异常值更加稳健

